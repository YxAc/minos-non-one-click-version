[configuration]
  # The raw files need to read when generating the configuration
  configuration.xsl=%{config_dir}/template/configuration.xsl
  log4j.xml=%{config_dir}/template/yarn/log4j.xml
  krb5.conf=%{config_dir}/krb5-hadoop.conf
  excludes=%{config_dir}/excludes
  pre.sh=%{config_dir}/template/yarn/pre.sh
  post.sh=%{config_dir}/template/yarn/post.sh

  [[core-site.xml]]
    # The core-site.xml config content
    fs.defaultFS=hdfs://%{cluster.hdfs_cluster}

    hadoop.http.staticuser.user=yarn
    hadoop.tmp.dir=/tmp/hadoop
    io.file.buffer.size=131072

    # security authentication switch
    hadoop.security.authentication=simple
    hadoop.security.authorization=false
    hadoop.security.use-weak-http-crypto=false

  [[hdfs-site.xml]]
    # The hdfs-site.xml config content
    dfs.nameservices=%{cluster.hdfs_cluster}
    dfs.ha.namenodes.%{cluster.hdfs_cluster}="host0,host1"
    dfs.namenode.rpc-address.%{cluster.hdfs_cluster}.host0=%{hdfs.namenode.0.host}:%{hdfs.namenode.0.base_port}
    dfs.namenode.rpc-address.%{cluster.hdfs_cluster}.host1=%{hdfs.namenode.1.host}:%{hdfs.namenode.1.base_port}
    dfs.client.failover.proxy.provider.%{cluster.hdfs_cluster}=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider

    dfs.client.read.shortcircuit.skip.auth=true
    dfs.client.read.shortcircuit=true

    # namenode security config
    dfs.namenode.kerberos.internal.spnego.principal=HTTP/hadoop@EXAMPLE.HADOOP
    dfs.namenode.keytab.file=/etc/hadoop/conf/hdfs.keytab
    dfs.namenode.kerberos.principal=hdfs/hadoop@EXAMPLE.HADOOP
    # secondary namenode security config
    dfs.secondary.namenode.kerberos.internal.spnego.principal=HTTP/hadoop@EXAMPLE.HADOOP
    dfs.secondary.namenode.keytab.file=/etc/hadoop/conf/hdfs.keytab
    dfs.secondary.namenode.kerberos.principal=hdfs/hadoop@EXAMPLE.HADOOP

    # datanode security config
    dfs.datanode.keytab.file=/etc/hadoop/conf/hdfs.keytab
    dfs.datanode.kerberos.principal=hdfs/hadoop@EXAMPLE.HADOOP

  [[mapred-site.xml]]
    # The mapred-site.xml config content
    mapreduce.jobhistory.address=0.0.0.0:%{historyserver.base_port}
    mapreduce.jobhistory.webapp.address=0.0.0.0:%{historyserver.base_port+1}
    mapreduce.shuffle.port=%{nodemanager.base_port+8}
    mapreduce.admin.user.env="LD_LIBRARY_PATH=%{nodemanager.current_package_dir}/lib/native:/usr/lib"

    mapreduce.framework.name=yarn
    yarn.app.mapreduce.am.staging-dir=/tmp/hadoop-yarn/staging
    mapreduce.jobhistory.keytab=/etc/hadoop/conf/yarn.keytab
    mapreduce.jobhistory.principal=yarn/hadoop@EXAMPLE.HADOOP

  [[yarn-site.xml]]
    # The yarn-site.xml config content
    # config resourcemanager
    yarn.resourcemanager.address=%{resourcemanager.0.host}:%{resourcemanager.0.base_port}
    yarn.resourcemanager.webapp.address=%{resourcemanager.0.host}:%{resourcemanager.0.base_port+1}
    yarn.resourcemanager.scheduler.address=%{resourcemanager.0.host}:%{resourcemanager.0.base_port+2}
    yarn.resourcemanager.resource-tracker.address=%{resourcemanager.0.host}:%{resourcemanager.0.base_port+3}
    yarn.resourcemanager.admin.address=%{resourcemanager.0.host}:%{resourcemanager.0.base_port+4}
    # config nodemanager
    yarn.nodemanager.address=0.0.0.0:%{nodemanager.base_port}
    yarn.nodemanager.webapp.address=0.0.0.0:%{nodemanager.base_port+1}
    yarn.nodemanager.localizer.address=0.0.0.0:%{nodemanager.base_port+2}
    # config proxy server
    yarn.web-proxy.address=%{proxyserver.0.host}:%{proxyserver.0.base_port+1}
    yarn.nodemanager.local-dirs=%{nodemanager.data_dirs}
    yarn.nodemanager.log-dirs=%{nodemanager.log_dir}
    yarn.resourcemanager.nodes.exclude-path=%{resourcemanager.run_dir}/excludes

    yarn.log-aggregation-enable=true
    yarn.nodemanager.aux-services=mapreduce.shuffle
    yarn.nodemanager.aux-services.mapreduce.shuffle.class=org.apache.hadoop.mapred.ShuffleHandler
    yarn.nodemanager.remote-app-log-dir=/var/log/hadoop-yarn/apps
    yarn.nodemanager.vmem-pmem-ratio=10
    yarn.nodemanager.log.retain-seconds=86400

    yarn.scheduler.capacity.root.queues=default
    yarn.scheduler.capacity.root.capacity=100
    yarn.scheduler.capacity.root.default.capacity=100

    # use CapacityScheduler
    yarn.resourcemanager.scheduler.class=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
    # use DominantResourceCalculator to support cpu scheduling
    yarn.scheduler.capacity.resource-calculator=org.apache.hadoop.yarn.server.resourcemanager.resource.DominantResourceCalculator

    yarn.resourcemanager.keytab=/etc/hadoop/conf/yarn.keytab
    yarn.resourcemanager.principal=yarn/hadoop@EXAMPLE.HADOOP
    yarn.nodemanager.keytab=/etc/hadoop/conf/yarn.keytab
    yarn.nodemanager.principal=yarn/hadoop@EXAMPLE.HADOOP
    yarn.web-proxy.keytab=/etc/hadoop/conf/yarn.keytab
    yarn.web-proxy.principal=yarn/hadoop@EXAMPLE.HADOOP

[arguments]

  [[service_common]]
    jvm_args='''
      -Xmx1024m
      -Xms768m
      -Xmn512m
      -XX:MaxDirectMemorySize=1024m
      -XX:MaxPermSize=128m
      -XX:+DisableExplicitGC
      -XX:+HeapDumpOnOutOfMemoryError
      -XX:HeapDumpPath=$log_dir
      -XX:+PrintGCApplicationStoppedTime
      -XX:+UseConcMarkSweepGC
      -XX:CMSInitiatingOccupancyFraction=80
      -XX:+UseMembar
      -verbose:gc
      -XX:+PrintGCDetails
      -XX:+PrintGCDateStamps
    '''

    system_properties='''
      -Djava.net.preferIPv4Stack=true
      -Dyarn.log.dir=$log_dir
      -Dyarn.pid=$pid
      -Dyarn.cluster=%{cluster.name}
      -Dyarn.log.level=%{cluster.log_level}
      -Dhadoop.policy.file=hadoop-policy.xml
      -Dhadoop.home.dir=$package_dir
      -Dhadoop.id.str=%{remote_user}
      -Djava.security.krb5.conf=$run_dir/krb5.conf
    '''

    main_entry='''
    '''

    extra_args='''
    '''

  [[resourcemanager]]
    jvm_args='''
      -Xloggc:$run_dir/stdout/resourcemanager_gc_${start_time}.log
    '''
    system_properties='''
      -Dproc_resourcemanager
    '''
    main_entry='''
      org.apache.hadoop.yarn.server.resourcemanager.ResourceManager
    '''

  [[nodemanager]]
    jvm_args='''
      -Xloggc:$run_dir/stdout/nodemanager_gc_${start_time}.log
    '''
    system_properties='''
      -Dproc_nodemanager
    '''
    main_entry='''
      org.apache.hadoop.yarn.server.nodemanager.NodeManager
    '''

  [[historyserver]]
    jvm_args='''
      -Xloggc:$run_dir/stdout/historyserver_gc_${start_time}.log
    '''
    system_properties='''
      -Dproc_historyserver
    '''
    main_entry='''
      org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer
    '''

  [[proxyserver]]
    jvm_args='''
      -Xloggc:$run_dir/stdout/proxyserver_gc_${start_time}.log
    '''
    system_properties='''
      -Dproc_proxyserver
    '''
    main_entry='''
      org.apache.hadoop.yarn.server.webproxy.WebAppProxyServer
    '''
